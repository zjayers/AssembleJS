# ARLO Environment Configuration
# ==============================
# Copy this file to .env and modify as needed
# DO NOT commit the actual .env file to version control

# ======================
# Server Configuration
# ======================

# Port for the ARLO server to listen on
PORT=8000

# Enable debug mode for additional logging (true/false)
DEBUG_MODE=false

# Log level (error, warn, info, debug, trace)
LOG_LEVEL=info

# ======================
# AI Provider Settings
# ======================

# Default AI provider to use (ollama, openai, or anthropic)
DEFAULT_AI_PROVIDER=ollama

# --- Ollama Configuration ---
# Local Ollama endpoint URL
OLLAMA_ENDPOINT=http://localhost:11434
# Default model to use with Ollama if not specified
OLLAMA_DEFAULT_MODEL=codellama:7b-code

# --- OpenAI Configuration ---
# API Key for OpenAI services
# OPENAI_API_KEY=your_openai_api_key_here
# Default model to use with OpenAI if not specified
# OPENAI_DEFAULT_MODEL=gpt-3.5-turbo
# OpenAI API endpoint (if using a proxy or non-standard endpoint)
# OPENAI_ENDPOINT=https://api.openai.com/v1/chat/completions

# --- Anthropic/Claude Configuration ---
# API Key for Anthropic/Claude services
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Default model to use with Anthropic if not specified
# ANTHROPIC_DEFAULT_MODEL=claude-3-sonnet-20240229
# Anthropic API endpoint (if using a proxy or non-standard endpoint)
# ANTHROPIC_ENDPOINT=https://api.anthropic.com/v1/messages

# ======================
# Database Settings
# ======================

# Path to store data files (collections, tasks, etc.)
# Default is .arlo/data if not specified
DATA_DIR=.arlo/data 

# Maximum number of items in response cache
CACHE_MAX_SIZE=1000

# Cache expiry time in milliseconds (default: 1 hour)
CACHE_EXPIRY_MS=3600000

# ======================
# Advanced Configuration
# ======================

# API request timeout in milliseconds (default: 2 minutes)
API_TIMEOUT=120000

# Maximum document length for knowledge storage
MAX_DOCUMENT_LENGTH=1000000

# Enable analytics tracking (true/false)
ENABLE_ANALYTICS=true

# Note: Agent-specific settings (provider, model, temperature) 
# are stored in the file system rather than environment variables
# to allow users to edit them through the UI.
# See /data/config/agents.json for these settings.

# ======================
# Development Settings
# ======================

# Enable mock mode for testing without actual AI providers (true/false)
MOCK_MODE=false

# Delay time for mock responses in milliseconds
MOCK_DELAY=1000